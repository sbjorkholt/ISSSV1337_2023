---
title: "Measuring concepts"
---

```{r, message = FALSE, warning = FALSE, echo = FALSE}
library(tidyverse)
library(haven)
```


Some concepts are quite concrete. Most people would for example agree that the concept of age is the years in which a person has lived. Life expectancy is the average years of living for each person in a country. The concept of "a generation" is tougher, but while we may not agree exactly on which group of years that fit into which generation, there is a lot of agreement on which categories of generations that exist[^1]. However, what about concepts such as "knowledge" or "well-being"? How to observe this in society?

[^1]: Silent generation, Boomers, Gen-X, Millenials, Gen-Z, etc.

The social sciences are frequently studying abstract concepts such as "trust", "democracy" or "conflict". Thus, a lot of effort is going into how to measure these concepts so that we can use them in quantitative studies. This "measurement process" involves at least three steps:

1.  Find the background concept you want to measure.
2.  Produce a **conceptualization** where you figure out how this concept differs or is the same as similar concepts (this usually involves reading articles and other research).
3.  Create a definition suitable for your problem statement.
4.  Figure out how you can observe this concept in the real world using existing sources of data, and create indicators based on this. This is called **operationalization**.
5.  Collect the data from the available sources and apply them to your units, creating a dataset. This is called **scoring cases**.
6.  Go back up the ladder step by step to check that you are actually measuring the background concept you wanted to study. This is called checking for **measurement validity**.

Here's an example of how one could go from a background concept to operationalized indicators:

```{r, out.width="100%", echo = FALSE, fig.show="hold"}
knitr::include_graphics("../figures/concepts1.jpg")
```

## Validity and reliability

In practice, creating good concepts, indicators and measures can be a long process because it involves a lot of back-and-forth. Adcock and Collier (2001) exemplifies this in the figure below, where the "measurement" part is going from concept to indicators to scores, and back.

```{r, out.width="100%", echo = FALSE, fig.show="hold"}
knitr::include_graphics("../figures/concepts2.png")
```

When measuring concepts, we should check that two things are in order:

1.  **Measurement validity**: The operationalized indicators should be a good representation of the concept are studying.

2.  **Measurement reliability:**: There should be little or no error in the measurement of the concept.

For example, if we were to measure the concept of *trust*, we might try to operationalize it by asking people a question about how much they trust others. This is, in fact, exactly what the [World Values Survey](https://www.worldvaluessurvey.org/wvs.jsp) does.

![](images/trust_wvs.PNG)

Thus we have a question with two answer options (beyond the options to not answer) -- either finding others trustworthy (scored 1) or not particularly trustworthy (scored 2). What does this look like when we score cases based on this question? Well, we get a score, either 1 or 2, for each person in the survey. 

```{r, echo = FALSE, message = FALSE, warning = FALSE, error = FALSE}

WVS <- readRDS("../datafolder/WVS_Wave_7.rds") %>%
  select(trust = Q57,
         age = Q262,
         sex = Q260,
         year = A_YEAR,
         country = B_COUNTRY_ALPHA) %>%
  filter(trust > 0) %>%
  mutate(trust = as.factor(trust),
         age = as.numeric(age),
         sex = as.factor(sex),
         year = as.numeric(year),
         country = as.factor(country)) %>%
  mutate(sex = ifelse(sex == 1, "Male",
                        ifelse(sex == 2, "Female", NA))) %>%
  mutate(country = countrycode::countrycode(sourcevar = country,
                                            origin = "iso3c",
                                            destination = "country.name")) %>%
  mutate(continent = countrycode::countrycode(sourcevar = country,
                                            origin = "country.name",
                                            destination = "continent"))

WVS %>%
  group_by(trust) %>%
  sample_n(10) %>%
  glimpse()

```

Questioning *measurement reliability* would involve asking whether something has happened that makes the recorded value different from the actual, real and true value out there. This could for example be because the question was badly made, and thus misinterpreted, or because the interviewer mumbled and the responded didn't catch what they said, or because the respondent was just by coincidence in a particularly trusty mood that day even though that is not how he or she usually feels. These are measurement errors. Usually, they lead to random variation, making the measure inaccurate, but not biased. 

When we question *measurement validity*, we ask whether the measured indicator actually reflects the concept. Is asking a question with two answer categories a good reflection of a person's trustfulness? Perhaps trust is more multifaceted, for example in that what you would answer depends on who you are asked to trust -- your neighbor, your work place, your politicians. And perhaps trust is not a black-and-white-thing, but rather more gradual. Maybe the answer categories should be, for example, from 1 to 7 where 1 is "do not trust at all" and 7 is "trust with my all my heart". These are typical questions to ask when investigating validity. If a measure is invalid, it will lead to bias.


## The concept

Picking the concept is part of the formulation of the research question. If we for example ask "Does income inequality lead to more crime?", we have at least two concepts, *income inequality* and *crime*. Naturally, we need to have a good understanding of what these two things mean before we can start investigating the relationship between them.

Diving into research, one might be surprised on the various ways of understanding a concept. A good concept should (1) not be vague (meaning that it should be precise and clear what it means) and (2) not ambiguous (meaning that one should be able to see the difference between this concept and something else) (Sartori 1970). Other criteria for good concepts are (1) familiarity, (2) resonance, (3) parsimony, (4) coherence, (5) differentiation, (6) depth, (7) theoretical utility, and (8) field utility (Gerring 1999). 

For example, while many researchers use the concept of "income inequality", there are many considerations to be made around this concept. What constitutes income (e.g. before or after tax)? Should we include wealth into this notion, or just income? And if we by "income inequality" are trying to refer to some sort of individual freedom, should we then also include non-monetary variables such as life satisfaction, standard of living and capabilities (Sen 1992)?

## The indicators

Which indicators we can produce depends on what data sources exist out there. Some sources of data to consider are:

-   Existing and available datasets
-   Conducting a survey
-   Collecting information from books, articles, webpages, or similar, preferably through a programmed script (i.e. automatically)

Using existing data sources is less time consuming, but if none exist, it might be worth trying to collect the data yourself. Finding new data sources and utilizing them can also yield novel measures. At the same time, it is often useful to try and find several measures for the same concept, so that you can check whether the measures give approximately the same scores for the same units. This increases measurement validity. For example, in the table below, we have four different indicators for the same concept -- income inequality.

```{r, out.width="100%", echo = FALSE, fig.show="hold"}
knitr::include_graphics("../figures/inequality_definition.PNG")
```

## Scoring cases

In the table, "N" stands for how many cases that are available from the data sources. This shows us how broadly the measure can be used to score cases. Which cases we have, depend on the unit of analysis. What is the objects that we are studying? It could be countries, persons, years, country-years, enterprises, organizations, documents, and so on. In the case of income inequality, our cases (observations, units) would most likely be countries or country-years.

## Measurement level



